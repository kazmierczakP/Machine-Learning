{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db9efcc2",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5533eb",
   "metadata": {},
   "source": [
    "# Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a88382",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5667e678",
   "metadata": {},
   "source": [
    "overfit = high variance\n",
    "\n",
    "underfit = high bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb8dc32",
   "metadata": {},
   "source": [
    "collect more data, select most important features, reduce size of parameters by regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19385539",
   "metadata": {},
   "source": [
    "#### regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d73dbb",
   "metadata": {},
   "source": [
    "add sum of wj^2 to the cost function penalising w so that they do not overfir the model, makes function more smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8015d8d",
   "metadata": {},
   "source": [
    "### Cost function with regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785c3e52",
   "metadata": {},
   "source": [
    "$$ J = \\frac{1}{2m} \\sum_{i=0}^{m-1} loss(f_w(x^{(i)}),y^{(i)}) + {\\color{blue}{\\frac{\\lambda}{2m} \\sum_{j=0}^{n-1}w^{2}_j}}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a08d7e",
   "metadata": {},
   "source": [
    "#### linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca41eae7",
   "metadata": {},
   "source": [
    "$$ J = \\frac{1}{2m} \\sum_{i=0}^{m-1} (f_w(x^{(i)})-y^{(i)})^{2} + {\\color{blue}{\\frac{\\lambda}{2m} \\sum_{j=0}^{n-1}w^{2}_j}}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72abf1f",
   "metadata": {},
   "source": [
    "#### logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8cc3b1",
   "metadata": {},
   "source": [
    "$$ J = -\\frac{1}{m} \\sum_{i=0}^{m-1} [y^{(i)}\\log(f_w(x^{(i)})) + (1-y^{(i)})\\log(1-f_w(x^{(i)}))] + {\\color{blue}{\\frac{\\lambda}{2m} \\sum_{j=0}^{n-1}w^{2}_j}}  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f739093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_linear(x,y,w,w0,lambda_=1):\n",
    "    rows,features=x.shape\n",
    "    cost=0\n",
    "    for row in range(rows):\n",
    "        cost+=(np.dot(x[row],w)+w0-y[row])**2\n",
    "    cost=cost/(2*rows)\n",
    "    \n",
    "    reg_cost=0\n",
    "    for feature in range(features):\n",
    "        reg_cost+=w[feature]**2\n",
    "    reg_cost=reg_cost*lambda_/(2*rows)\n",
    "    cost+=reg_cost\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f45dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_logistic(x,y,w,w0,lambda_=1):\n",
    "    cost=0\n",
    "    rows,features=x.shape\n",
    "    for row in range(rows):\n",
    "        f=sigmoid(np.dot(x[row],w)+w0)\n",
    "        cost+=-y[row]*np.log(f)-(1-y[row])*np.log(1-f)\n",
    "    cost=cost/rows\n",
    "    \n",
    "    reg_cost=0\n",
    "    for feature in range(features):\n",
    "        reg_cost+=w[feature]**2\n",
    "    reg_cost=reg_cost*lambda_/(2*rows)\n",
    "    cost+=reg_cost\n",
    "    return cost\n",
    "def sigmoid(z):\n",
    "    y=1/(1+np.exp(-z))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccf19a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e594974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost linear: 0.07917239320214275\n",
      "Cost logistic: 0.6850849138741673\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x=np.random.rand(5,6)\n",
    "y=np.array([0,1,0,1,0])\n",
    "w=np.random.rand(x.shape[1]).reshape(-1)-0.5\n",
    "w0=0.5\n",
    "lambda_=0.7\n",
    "cost_lin=cost_linear(x,y,w,w0,lambda_)\n",
    "cost_log=cost_logistic(x,y,w,w0,lambda_)\n",
    "print(f'Cost linear: {cost_lin}')\n",
    "print(f'Cost logistic: {cost_log}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989eeff0",
   "metadata": {},
   "source": [
    "### gradient descent with regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aa9ed8",
   "metadata": {},
   "source": [
    "$$ dw_j=\\frac{1}{m} \\sum_{i=0}^{m-1} (f_w(x^{(i)})-y^{(i)})*x^{(i)}_j + {\\color{blue}{\\frac{\\lambda}{m}w_j}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08481025",
   "metadata": {},
   "source": [
    "$$ dw_0=\\frac{1}{m} \\sum_{i=0}^{m-1} (f_w(x^{(i)})-y^{(i)})*x^{(i)}_j $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c130cbb9",
   "metadata": {},
   "source": [
    "#### linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f70b06",
   "metadata": {},
   "source": [
    "$$ f_w(x^{(i)})=w \\cdot x^{(i)}+b $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036466ea",
   "metadata": {},
   "source": [
    "#### logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88c63ea",
   "metadata": {},
   "source": [
    "$$ f_w(x^{(i)})=\\dfrac {1}{1+e^{-(w_0+w_1x_1+w_2x_2+...+w_jx_j)}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "785d2158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_linear(x,y,w,w0,lambda_):\n",
    "    rows,features=x.shape\n",
    "    dw=np.zeros(features)\n",
    "    dw0=0\n",
    "    for feature in range(features):\n",
    "        for row in range(rows):\n",
    "            dw[feature]+=(np.dot(x[row],w)+w0-y[row])*x[row][feature]\n",
    "    for row in range(rows):\n",
    "        dw0+=(np.dot(x[row],w)+w0-y[row])\n",
    "    dw=dw/rows\n",
    "    dw0=dw0/rows\n",
    "    for feature in range(features):\n",
    "        dw[feature]+=(lambda_/rows)*w[feature]\n",
    "    return dw,dw0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "306ab763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_logistic(x,y,w,w0,lambda_):\n",
    "    rows,features=x.shape\n",
    "    dw=np.zeros(features)\n",
    "    dw0=0\n",
    "    for feature in range(features):\n",
    "        for row in range(rows):\n",
    "            dw[feature]+=(sigmoid(np.dot(x[row],w)+w0)-y[row])*x[row][feature]\n",
    "    for row in range(rows):\n",
    "        dw0+=sigmoid(np.dot(x[row],w)+w0)-y[row]\n",
    "    dw=dw/rows\n",
    "    dw0=dw0/rows\n",
    "    for feature in range(features):\n",
    "        dw[feature]+=(lambda_/rows)*w[feature]\n",
    "    return dw,dw0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a25a486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient linear: dw: [0.29653215 0.49116796 0.21645878] dw0: 0.6648774569425726\n",
      "Gradient logistic:: dw: [0.17380013 0.32007508 0.10776313] dw0: 0.341798994972791\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x=np.random.rand(5,3)\n",
    "y=np.array([0,1,0,1,0])\n",
    "w=np.random.rand(x.shape[1])\n",
    "w0=0.5\n",
    "lambda_=0.7\n",
    "dw_lin,dw0_lin=gradient_linear(x,y,w,w0,lambda_)\n",
    "dw_log,dw0_log=gradient_logistic(x,y,w,w0,lambda_)\n",
    "print(f'Gradient linear: dw: {dw_lin} dw0: {dw0_lin}')\n",
    "print(f'Gradient logistic:: dw: {dw_log} dw0: {dw0_log}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0087e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
